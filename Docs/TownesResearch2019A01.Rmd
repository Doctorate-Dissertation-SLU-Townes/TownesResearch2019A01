---
title: "R Notebook: Improving Construct Validity in Studies of Technology Transfer"
author: "Malcolm S. Townes"
date: '(`r format(Sys.time(), "%B %d, %Y")`)'
output: 
    github_document: default
    html_notebook: default
    always_allow_html: yes
---

## Introduction
This is an R Notebook for an investigation on improving construct validity in studies of technology transfer.

## Project Set Up
The following code chunk enables the R Notebook to integrate seemlessly with the project organization format. This is normally included in the R Notebook to simplify file calls and enable file portability but it has been causing an error. Per Dr. Christopher Prener of Saint Louis University, the error is generated because the `here::here()` function has not been tested with certain combinations of functions. To work around this problem, I've embedded the `here()` function where I enter a file path when necessary.

```{r setup-project}
knitr::opts_knit$set(root.dir = here::here())
```

## Load Dependencies
The following code chunk loads package dependencies required to perform the necessary tasks. Basic tasks include importing, reading, wrangling, and cleaning data; selecting a subset of the data; checking for unique observations, and analyzing missing data. 
```{r load-dependencies}
library(tidyverse) # loads the basic R packages
library(here) # enables file portability
library(readr) # functions for reading data
library(dplyr) # functions for data wrangling
library(janitor) # functions for data cleaning
library(naniar) # functions for analyzing missing data
library(ggplot2) # functions for data visualizations
library(boot) # functions for regression analysis
library(MASS) # functions for ordered logistic or probit regression
library(broom) # functions for tidying ordinal logistic regression models
```

## Load Raw Data
The following code chunk imports the raw data from the `txt` file for the NBER data set for the period 1963 to 1999.
```{r import-data}
setwd("E:/TownesResearch2019A01")
DataRaw <- read.table("DataRaw/NBERpatents1963to1999/apat63_99.txt", sep = ",", header = TRUE, fill = TRUE, dec = ".")
```

## Subset Data
The following code chunk creates a subset of the data for the period 1990 through 1995.
```{r subset-data-90-95}
DataRaw %>% # subset data
  filter(GYEAR>=1990) %>%
  filter(GYEAR<=1995) -> DataSubset90to95
DataSubset90to95 <- as_tibble(DataSubset90to95) # convert data frame to tibble
```

## Inspect Subset Data
The following code chunk evaluates the data sample to determine if additional data cleaning is necessary.  It first checks for missing data for each variable.  It then checks for missing data for each variable in each observation.  Then it checks for duplicate observations with the `PATENT` variable to determine if that variable can be used as a unique identifier for each observation.  Finally, it checks for duplicate observations across all variables to ensure that each observation is unique.
```{r inspect-data-90-95}
miss_var_summary(DataSubset90to95, order = TRUE)
miss_case_summary(DataSubset90to95, order = TRUE)
get_dupes(DataSubset90to95, PATENT)
get_dupes(DataSubset90to95)
```

## Sample Data
The following code chunk takes a sample of 2,000 cases from the data subset for the period 1990 through 1995.
``` {r sample-90-95}
set.seed(1972)
Sample90to95 <- sample(1:nrow(DataSubset90to95), size = 2000, replace = TRUE, prob = NULL)
Sample90to95 <- DataSubset90to95[Sample90to95,]
Sample90to95 <- as_tibble(Sample90to95)
```

## Clean Data
Based on the results of the previous code chunck, I did not perform any additional cleaning of the data sample.
```{r view-data}
View(Sample90to95, "Cleaned Sample Data 1990 to 1995")
```

## Observation Counts
The following code chunk determines the number of observations for each outcome of each independent variable to determine if the sample size is large enough for logistic regression analysis, which requires at least 10 observations for the least frequent outcome for each independent variable.
```{r sample-size}
Sample90to95 %>%
  group_by(CRECEIVE) %>%
  summarize(n())

Sample90to95 %>%
  group_by(APPYEAR) %>%
  summarize(n())

Sample90to95 %>%  
  group_by(CAT) %>%
  summarize(n())

Sample90to95 %>%    
  group_by(CMADE) %>%
  summarize(n())

Sample90to95 %>%  
  group_by(CLAIMS) %>%
  summarize(n())

Sample90to95 %>%  
  group_by(ORIGINAL) %>%
  summarize(n())

Sample90to95 %>%  
  group_by(GENERAL) %>%
  summarize(n())

Sample90to95 %>%  
  group_by(RATIOCIT) %>%
  summarize(n())
```

## Histograms
The following code chunk displays histograms for the variables of primary interest to enable visual inspection of the data for normal distributions.
```{r histograms}
histoCRECEIVE <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(CRECEIVE))
ggsave(here("results", "histogramCRECEIVE.png"), dpi = 300)

histoAPPYEAR <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(APPYEAR))
ggsave(here("results", "histogramAPPYEAR.png"), dpi = 300)

histoCAT <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(CAT))
ggsave(here("results", "histogramCAT.png"), dpi = 300)

histoCMADE <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(CMADE))
ggsave(here("results", "histogramCMADE.png"), dpi = 300)

histoCLAIMS <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(CLAIMS))
ggsave(here("results", "histogramCLAIMS.png"), dpi = 300)

histoORIGINAL <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(ORIGINAL))
ggsave(here("results", "histogramORIGINAL.png"), dpi = 300)

histoGENERAL <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(GENERAL))
ggsave(here("results", "histogramGENERAL.png"), dpi = 300)

histoRATIOCIT <- ggplot() +
  geom_histogram(Sample90to95, mapping = aes(RATIOCIT))
ggsave(here("results", "histogramRATIOCIT.png"), dpi = 300)
```

## Q-Q Plots
The following code chunk displays Quantile-Quantile (Q-Q) plots to check for normal distribution in the data sample for each variable of primary interest.
```{r qq-plots}
setwd("D:/TownesResearch2019A01")

png(filename = "Results/QQplotCReceive.png")
qqnorm(Sample90to95$CRECEIVE, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for CRECEIVE", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles", plot.it = TRUE)
qqline(Sample90to95$CRECEIVE, col = "green", lwd = 2, plot.it = TRUE)
dev.off()

png(filename = "Results/QQplotAPPYEAR.png")
qqnorm(Sample90to95$APPYEAR, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for APPYEAR", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$APPYEAR, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotCAT.png")
qqnorm(Sample90to95$CAT, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for CAT", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$CAT, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotCMADE.png")
qqnorm(Sample90to95$CMADE, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for CMADE", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$CMADE, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotCLAIMS.png")
qqnorm(Sample90to95$CLAIMS, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for CLAIMS", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$CLAIMS, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotORIGINAL.png")
qqnorm(Sample90to95$ORIGINAL, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for ORIGINAL", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$ORIGINAL, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotGENERAL.png")
qqnorm(Sample90to95$GENERAL, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for GENERAL", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$GENERAL, col = "green", lwd = 2)
dev.off()

png(filename = "Results/QQplotRATIOCIT.png")
qqnorm(Sample90to95$RATIOCIT, pch = 1, frame = FALSE, 
       main = "Normal Q-Q Plot for RATIOCIT", xlab = "Theoretical Quantiles", ylab = "Sample Quantiles")
qqline(Sample90to95$RATIOCIT, col = "green", lwd = 2)
dev.off()
```

## Central Tendency
The following code chunk calculates measures of central tendency in the sample data for each of the variables of primary interest.
```{r central-tendency}
summary(Sample90to95)
```

## Pairwise Correlation Coefficients
The following code chunk calculates the pairwise correlation coefficients for all variables in the sample data using the Pearson product-moment correlation function.
```{r cor-matrix}
Sample90to95 %>%
  dplyr::select(-c(PATENT, GDATE, COUNTRY, POSTATE, ASSIGNEE, ASSCODE)) %>%
  as_tibble() -> Sample90to95cor
cor(Sample90to95cor)
pairs(Sample90to95cor)
```

## Scatter Plots
The following code chunk displays scatter plots with `CRECEIVE` as the dependent variable against each of the the primary independent variables of interest to visually inspect for linear relationships between the dependent variable and each of the independent variables of primary interest.
```{r scatter-plots}
ggplot() +
  geom_point(Sample90to95, mapping = aes(x = APPYEAR, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyAPPYEAR.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = CAT, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyCAT.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = CMADE, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyCMADE.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = CLAIMS, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyCLAIMS.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = ORIGINAL, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyORIGINAL.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = GENERAL, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyGENERAL.png"), dpi = 300)

ggplot() +
  geom_point(Sample90to95, mapping = aes(x = RATIOCIT, y = CRECEIVE))
ggsave(here("results", "scatterCRECEIVEbyRATIOCIT.png"), dpi = 300)
```

## Binary Logistic Regression Analysis
The following code chunk performs a binary logistic regression analysis on the data sample. It first creates a new variable called `CRECbinomial` that converts the `CRECEIVE` variable into a dichotomous variable. It then uses the new dichotomous variable as the dependent variable in the binary logistic regression.
```{r binary-regression}
Sample90to95 %>%
  mutate(CRECbinomial = if(CRECEIVE == 0) {
    CRECbinomial = 0} else {CRECbinomial = 1}) -> Sample90to95
logitCRECEIVE <- glm(CRECbinomial ~ APPYEAR + CAT + CMADE + CLAIMS + ORIGINAL + GENERAL + RATIOCIT, data = Sample90to95, family = binomial)
summary(logitCRECEIVE)
```

## Ordinal Logistic Regression Analysis
The following code chunk performs an ordinal logistic regression analysis on the data sample using `CRECEIVE` as the dependent variable.
```{r ordinal-regression}
CRECordinal <- polr(as.factor(CRECEIVE) ~ APPYEAR + CAT + CMADE + CLAIMS + ORIGINAL + GENERAL + RATIOCIT, data = Sample90to95, Hess = TRUE, model = TRUE, method = "logistic")
summary(CRECordinal)
```

## Save Data
The following code chunk saves the final cleaned data that was used in the analysis.
```{r save-data}
write.csv(Sample90to95, here("Data/DataClean/NBERpatents1963to1999/NBERPatCit90to95Sample.csv"), append = FALSE)
```
